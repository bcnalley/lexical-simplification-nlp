{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516791e9-7388-4ea7-8a08-9a2a938a65e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 501 words.\n",
      "There are 476 words.\n",
      "There are 473 words.\n",
      "There are 497 words.\n",
      "There are 491 words.\n",
      "        TTR   Root TTR   Log TTR  Mass TTR      MSTR     MATTR       HDD  \\\n",
      "0  0.428008   9.637308  0.863753  0.050368  0.732000  0.743886  0.776827   \n",
      "1  0.422037   9.256003  0.860317  0.052079  0.720000  0.719583  0.756950   \n",
      "2  0.450939   9.869292  0.870956  0.048145  0.748889  0.746093  0.779907   \n",
      "3  0.430279   9.640552  0.864387  0.050214  0.726000  0.732053  0.778521   \n",
      "4  0.461847  10.306546  0.875613  0.046117  0.742222  0.750334  0.787369   \n",
      "\n",
      "        MTLD  MTLD wrap    MTLD bi  # words  Custom AG  \n",
      "0  54.412078  53.437870  53.505305    501.0   1.687639  \n",
      "1  46.865400  46.012474  45.999370    476.0   1.595863  \n",
      "2  55.836036  53.835073  52.565840    473.0   1.644882  \n",
      "3  50.355225  50.498008  48.588108    497.0   1.517494  \n",
      "4  59.222276  58.385542  55.167971    491.0   1.747632  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import spacy\n",
    "from lexical_diversity import lex_div as ld\n",
    "import pandas as pd\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "import math\n",
    "\n",
    "# If using local Jupyter Notebook\n",
    "import nbimporter\n",
    "from Custom_Adv_G import c_adv_guiraud\n",
    "\n",
    "# If using Google Colab\n",
    "#%run /content/drive/MyDrive/Example/Functions/Custom_Adv_G.ipynb import c_adv_guiraud\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "scores_1 = pd.DataFrame(columns = ['TTR', 'Root TTR', 'Log TTR', 'Mass TTR', 'MSTR', 'MATTR', 'HDD', 'MTLD', 'MTLD wrap', 'MTLD bi', '# words', 'Custom AG'])\n",
    "\n",
    "# read in Group 1 stories\n",
    "for p in Path('Data/Group 1').glob('*.txt'):\n",
    "    num_words = 0\n",
    "    with p.open(encoding = 'UTF-8') as f:\n",
    "        story = f.read()\n",
    "        \n",
    "        lines = story.split()\n",
    "        num_words = len(lines)\n",
    "        \n",
    "        story_nlp  = nlp(story)\n",
    "            \n",
    "        text = []\n",
    "        \n",
    "        # tokenization\n",
    "        for i in story_nlp:\n",
    "            if i.text != '\\n' and not i.is_punct: \n",
    "                text.append(i.lemma_)\n",
    "        \n",
    "        story_db = []\n",
    "        \n",
    "        ttr = ld.ttr(text) #basic TTR\n",
    "        story_db.append(ttr)\n",
    "            \n",
    "        rttr = ld.root_ttr(text) # root TTR\n",
    "        story_db.append(rttr)\n",
    "        \n",
    "        lttr = ld.log_ttr(text) # log TTR\n",
    "        story_db.append(lttr)\n",
    "        \n",
    "        mttr = ld.maas_ttr(text) # Maas TTR or Mass?\n",
    "        story_db.append(mttr)\n",
    "        \n",
    "        msttr = ld.msttr(text) # mean segmental TTR with default 50 word window\n",
    "        story_db.append(msttr)\n",
    "       \n",
    "        mattr = ld.mattr(text) # moving average TTR with default 50 word segment\n",
    "        story_db.append(mattr)\n",
    "        \n",
    "        hdd = ld.hdd(text) # hypergeometric distribution D\n",
    "        story_db.append(hdd)\n",
    "       \n",
    "        mtld = ld.mtld(text) # measure of lexical textual diversity\n",
    "        story_db.append(mtld)\n",
    "        \n",
    "        mtldw = ld.mtld_ma_wrap(text) # measure of lexical textual diversity (moving average, wrap)\n",
    "        story_db.append(mtldw)\n",
    "        \n",
    "        mtldb = ld.mtld_ma_bid(text) # measure of lexical textual diversity (moving average, bidirectional)\n",
    "        story_db.append(mtldb)\n",
    "        \n",
    "        story_db.append(num_words)\n",
    "        \n",
    "        cadvg = c_adv_guiraud(text) # customized Advanced Guiraud\n",
    "        story_db.append(cadvg)\n",
    "        \n",
    "        scores_1.loc[len(scores_1)] = story_db\n",
    "        \n",
    "    print(\"There are \" + str(num_words) + \" words.\")\n",
    " \n",
    "print(scores_1)\n",
    "\n",
    "scores_1.to_csv(r'Data/scores_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
